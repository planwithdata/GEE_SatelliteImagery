{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5db8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsingh\\AppData\\Local\\Temp\\ipykernel_26604\\1871540633.py:74: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(x_train, y_train)\n",
      "C:\\Users\\rsingh\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "C:\\Users\\rsingh\\AppData\\Local\\Temp\\ipykernel_26604\\1871540633.py:358: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  Scn_Output.to_file(driver = 'ESRI Shapefile', filename =r'Scn_Output.shp', crs = \"EPSG:4326\" )\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# Get Current Directory\n",
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Risk_WF\\\\Model_Files\\\\Training_Data')\n",
    "\n",
    "current_taz_data_3 = gpd.read_file(r'ModelTaz.shp')\n",
    "\n",
    "current_taz_data_2 = gpd.read_file(r'TAZ_By_LY_WF.shp')\n",
    "\n",
    "current_taz_data = pd.read_excel(r'TAZ_By_LY_WF_excel_2.xlsx')\n",
    "\n",
    "\n",
    "## Naming Columns to match\n",
    "current_taz_data.rename (columns = {'TAZ':'Model_TAZ'},inplace = True)\n",
    "\n",
    "\n",
    "current_taz_data_3.rename (columns = {'TOPOP_17':'TOT_POP','HH_17':'HH'},inplace = True)\n",
    "\n",
    "current_taz_data_3.iloc[:,[1,9,17]]\n",
    "\n",
    "current_taz_data_new=pd.merge(current_taz_data,current_taz_data_3.iloc[:,[1,9,17]],on = 'Model_TAZ', how = 'inner')\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "## Feature Creation : Population Density\n",
    "current_taz_data_new['POP_Den'] = current_taz_data_new['TOT_POP']/current_taz_data_new['ACRES']\n",
    "\n",
    "\n",
    "\n",
    "# In[262]:\n",
    "\n",
    "\n",
    "x = current_taz_data_new.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14,15,25,26]]  \n",
    "\n",
    "\n",
    "x = x.replace(np.nan, 0)\n",
    "\n",
    "y = current_taz_data_new.iloc[:,[-7]] ## Summarized Areas\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size = 0.3,random_state = 2)\n",
    "\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training data\n",
    "regressor = RandomForestRegressor(n_estimators=800, random_state=42)\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# In[321]:\n",
    "\n",
    "\n",
    "# ## For Training Data\n",
    "\n",
    "# r_square=regressor.score(x_train, y_train)\n",
    "# r2_n=len(y_train)\n",
    "# r2_k=x_train.shape[1]\n",
    "# adjusted_r_square = 1 - (1-r_square)*(r2_n-1)/(r2_n-r2_k-1)\n",
    "# print(r_square)\n",
    "# print(adjusted_r_square)\n",
    "\n",
    "\n",
    "# # In[322]:\n",
    "\n",
    "\n",
    "# output = x_train\n",
    "# y_pred_train = regressor.predict(x_train)\n",
    "# np.set_printoptions(precision=2)\n",
    "# output['y_pred_train']=y_pred_train\n",
    "# output['y_train']=y_train\n",
    "# output.iloc[:,[-1,-2]].head(10)\n",
    "\n",
    "\n",
    "# # In[323]:\n",
    "\n",
    "\n",
    "# ## For Training Data\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# mse = mean_squared_error(output.iloc[:,[-1]], output.iloc[:,[-2]])  ## (y_true, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# print(\"RMSE (Training Data) = \",rmse)\n",
    "\n",
    "\n",
    "# # In[310]:\n",
    "\n",
    "\n",
    "# std = output.iloc[:,[-1]].std()\n",
    "# print(\"StdDev_TrainData = \",std)\n",
    "\n",
    "\n",
    "# # In[311]:\n",
    "\n",
    "\n",
    "# y_max = output.iloc[:,[-1]].max()\n",
    "# print(\"y_max = \",y_max)\n",
    "# y_min = output.iloc[:,[-1]].min()\n",
    "# print(\"y_min = \",y_min)\n",
    "# nrmse = rmse/(y_max - y_min)  # Normalized RMSE for comparison with other models\n",
    "# print(\"Normalized RMSE (Training Data)= \", nrmse)\n",
    "\n",
    "\n",
    "# In[324]:\n",
    "\n",
    "\n",
    "x_train = x_train.iloc[:,0:15]\n",
    "\n",
    "\n",
    "# # In[325]:\n",
    "\n",
    "\n",
    "# x_train.columns\n",
    "\n",
    "\n",
    "# # In[211]:\n",
    "\n",
    "\n",
    "# ### Need to make a better split that is a better representation of the whole data\n",
    "\n",
    "\n",
    "# # In[326]:\n",
    "\n",
    "\n",
    "# # For Test Data\n",
    "\n",
    "# r_square=regressor.score(x_test, y_test)\n",
    "# r2_n=len(y_test)\n",
    "# r2_k=x_test.shape[1]\n",
    "# adjusted_r_square = 1 - (1-r_square)*(r2_n-1)/(r2_n-r2_k-1)\n",
    "# print(r_square)\n",
    "# print(adjusted_r_square)\n",
    "\n",
    "\n",
    "# # In[317]:\n",
    "\n",
    "\n",
    "# x_test\n",
    "\n",
    "\n",
    "# # In[331]:\n",
    "\n",
    "\n",
    "# #x_test = x_test.iloc[:,0:15]\n",
    "\n",
    "\n",
    "# # In[343]:\n",
    "\n",
    "\n",
    "# x_test = x_test.iloc[:,0:15]\n",
    "# output=x_test\n",
    "# y_pred_test = regressor.predict(x_test)\n",
    "# np.set_printoptions(precision=2)\n",
    "# output['y_pred_test']=y_pred_test\n",
    "# output['y_test']=y_test\n",
    "# output.iloc[:,[-1,-2]].head(30)\n",
    "\n",
    "\n",
    "# # In[274]:\n",
    "\n",
    "\n",
    "# # For Test Data\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# mse = mean_squared_error(output.iloc[:,[-1]], output.iloc[:,[-2]])  ## (y_true, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# print(\"RMSE (Test Data)= \",rmse)\n",
    "\n",
    "\n",
    "# # In[275]:\n",
    "\n",
    "\n",
    "# std = output.iloc[:,[-1]].std()\n",
    "# print(\"StdDev_TestData = \",std)\n",
    "\n",
    "\n",
    "# # In[276]:\n",
    "\n",
    "\n",
    "# y_max = output.iloc[:,[-1]].max()\n",
    "# print(\"y_max = \",y_max)\n",
    "\n",
    "\n",
    "# # In[277]:\n",
    "\n",
    "\n",
    "# y_min = output.iloc[:,[-1]].min()\n",
    "# print(\"y_min = \",y_min)\n",
    "\n",
    "\n",
    "# # In[278]:\n",
    "\n",
    "\n",
    "# nrmse = rmse/(y_max - y_min)  # Normalized RMSE for comparison with other models\n",
    "# print(\"Normalized RMSE (Test Data) = \", nrmse)  # Normalized RMSE for comparison with other models\n",
    "\n",
    "\n",
    "# In[279]:\n",
    "\n",
    "\n",
    "# # Obtain feature importances\n",
    "# feature_importances = regressor.feature_importances_\n",
    "# # Printing Variable Coefficients\n",
    "# for feature, importance in zip(x_train.columns, feature_importances):\n",
    "#     print(f\"{feature}: {importance}\")\n",
    "\n",
    "\n",
    "\n",
    "x_test = x_test.iloc[:,0:15]\n",
    "\n",
    "\n",
    "\n",
    "# os.chdir('C:\\\\Users\\\\rsingh\\\\OneDrive - PlanRVA\\\\Documents\\\\SP_ResiliencyModel\\\\Taz_2050 File\\\\Model50Taz')\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "os.chdir('C:\\\\Risk_WF\\\\Model_Files\\\\Paste_Input_File_Here\\\\Base TAZ SHP')\n",
    "Base_TAZ = gpd.read_file(r'Base_TAZ.shp')\n",
    "Base_TAZ.columns\n",
    "\n",
    "os.chdir('C:\\\\Risk_WF\\\\Model_Files\\\\Paste_Input_File_Here')\n",
    "input_data = pd.read_excel(r'Input_WF.xlsx')\n",
    "#input_data = pd.read_excel(r'RSLAM_Mock_Resiliency_WF_Input.xlsx')\n",
    "#input_data.head()\n",
    "\n",
    "if pd.notna(input_data.columns[3]):\n",
    "    try:\n",
    "        numeric_value = pd.to_numeric(input_data.columns[3])\n",
    "        if not np.isnan(numeric_value):\n",
    "            input_data.columns = input_data.iloc[0, :]\n",
    "            input_data = input_data.drop(index=0)\n",
    "        else:\n",
    "            pass  # No action is needed\n",
    "        \n",
    "    except ValueError:\n",
    "        pass  # No action is needed\n",
    "else:\n",
    "    input_data.columns = input_data.iloc[0, :]\n",
    "    input_data = input_data.drop(index=0)\n",
    "\n",
    "\n",
    "#input_data.head()\n",
    "\n",
    "input_data = input_data.replace(np.nan, 0)\n",
    "\n",
    "input_data['TAZ'] = input_data['TAZ'].astype(int)\n",
    "\n",
    "Base_TAZ = Base_TAZ.replace(np.nan, 0)\n",
    "\n",
    "Base_TAZ['TAZ'] = Base_TAZ['TAZ'].astype(int)\n",
    "\n",
    "#print(input_data.dtypes)\n",
    "\n",
    "forecasted_taz_data = pd.merge(Base_TAZ, input_data, on = 'TAZ', how = 'inner')\n",
    "\n",
    "# forecasted_taz_data.columns\n",
    "\n",
    "#forecasted_taz_data.head()\n",
    "\n",
    "#forecasted_taz_data.columns\n",
    "\n",
    "forecasted_taz_data['POP_Den'] = forecasted_taz_data['TOT_POP']/forecasted_taz_data['TAZ_ACRES_Ar']\n",
    "#x_test = forecasted_taz_data.iloc[:,[8,9,10,11,12,13,14,15,16,17,18,19,20,-8,-1]]\n",
    "\n",
    "x_test = pd.DataFrame()\n",
    "\n",
    "x_test['L_D_RE'] = forecasted_taz_data['L_D_RE_Ar']  \n",
    "x_test['M_D_RE_SF'] = forecasted_taz_data['M_D_RE_SF_Ar']  \n",
    "x_test['M_D_RE_MF'] = forecasted_taz_data['M_D_RE_MF_Ar']  \n",
    "x_test['H_D_RE'] = forecasted_taz_data['H_D_RE_Ar']  \n",
    "x_test['MU'] = forecasted_taz_data['MU_Ar']  \n",
    "x_test['COM'] = forecasted_taz_data['COM_Ar']  \n",
    "x_test['INS'] = forecasted_taz_data['INS_Ar']  \n",
    "x_test['OF'] = forecasted_taz_data['OF_Ar']  \n",
    "x_test['IND'] = forecasted_taz_data['IND_Ar']  \n",
    "x_test['Other'] = forecasted_taz_data['Other_Ar']  \n",
    "x_test['AG'] = forecasted_taz_data['AG_Ar']  \n",
    "x_test['FO'] = forecasted_taz_data['FO_Ar']  \n",
    "x_test['PA'] = forecasted_taz_data['PA_Ar']  \n",
    "x_test['HH'] = forecasted_taz_data['HH']  \n",
    "x_test['POP_Den'] = forecasted_taz_data['POP_Den']  \n",
    "\n",
    "\n",
    "#x_test.columns\n",
    "\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "forecasted_taz_data['Future_Summ_Area'] = y_pred\n",
    "\n",
    "forecasted_taz_data['Future_Acr_Aff'] = (forecasted_taz_data['Future_Summ_Area']*100)/forecasted_taz_data['TAZ_ACRES_Ar'] \n",
    "\n",
    "\n",
    "forecasted_taz_data['Future_ACR_Aff_Prop']=forecasted_taz_data['Future_Summ_Area']/forecasted_taz_data['TAZ_ACRES_Ar']\n",
    "\n",
    "#forecasted_taz_data.iloc[:,[22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37]]\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "for i in range(35):\n",
    "\n",
    "    #col = forecasted_taz_data.iloc[:,8+i]\n",
    "    if forecasted_taz_data.columns[i+8] == 'JUR':\n",
    "        continue\n",
    "    elif ((forecasted_taz_data.columns[i+8] == 'TOT_POP')|(\"EMP\" in forecasted_taz_data.columns[i+8])|(\"HH\" in forecasted_taz_data.columns[i+8])):\n",
    "        forecasted_taz_data['Scn_'+forecasted_taz_data.columns[i+8]] = round(forecasted_taz_data.iloc[:,8+i].astype(float)*forecasted_taz_data['Future_ACR_Aff_Prop'],0)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    #forecasted_taz_data['Scn_'+forecasted_taz_data.columns[i+8]] = forecasted_taz_data.iloc[:,8+i].astype(float)*forecasted_taz_data['Future_ACR_Aff_Prop']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "#Scn_Output = forecasted_taz_data.drop( columns = ['Scn_Parcel_ACR_Ar','Scn_TAZ_ACRES_Ar'])\n",
    "Scn_Output = forecasted_taz_data\n",
    "\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "os.chdir('C:\\\\Risk_WF\\\\Model_Files\\\\Output_Files\\\\Output_Shp')\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "Scn_Output.to_file(driver = 'ESRI Shapefile', filename =r'Scn_Output.shp', crs = \"EPSG:4326\" )\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "Scn_Output.to_excel('Scn_Output.xlsx')\n",
    "\n",
    "#fig, ax = plt.subplots(figsize=(12, 10))\n",
    "#forecasted_taz_data.plot(column='Future_Acr_Aff', legend=True, ax=ax)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 10))\n",
    "# forecasted_taz_data.plot(column='Future_Summ_Area', legend=True, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
